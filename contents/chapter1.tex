%% PART I %%
\part{Statistical Learning Theory}

%% CHAPTER 1 %%
\chapter{Formal Setting}
\label{ch: formal setting}

The primary object in much of what we will cover is the \emph{joint distribution} $\P_{(X, Y)}$ of two random variables $X \colon \Omega \to \mathcal{X}$ and $Y \colon \Omega \to \mathcal{Y}$ defined on some probability space $(\Omega, \mathcal{A}, \P)$. Theoretically, these random variables can take values in arbitrary measurable spaces $(\mathcal{X}, \mathcal{F}_{\mathcal{X}})$ and $(\mathcal{Y}, \mathcal{F}_{\mathcal{Y}})$, respectively. In practice, these will most often be some $d$-dimensional Euclidean space $\R^d$ equipped with the Borel $\sigma$-algebra $\mathcal{B}(\R^d)$. Recall that, in the abstract setting, the \emph{joint cumulative distribution function} $F_{(X, Y)}$ is given by
\[
    \highlightMath{
        F_{(X, Y)}(A \times B) = \Pr{X \in A, Y \in B}, \quad A \in \mathcal{F}_{\mathcal{X}}, B \in \mathcal{F}_{\mathcal{Y}}.
    }
\]
If $X$ and $Y$ take values in $R^k$ and $\R^l$, respectively, we write
\[
    \highlightMath{
        F_{(X, Y)}(\mathbf{x}, \mathbf{y}) = \Pr{X_1 \leq x_1, \dots, X_k \leq x_k, Y_1 \leq y_1, \dots, Y_l \leq y_l}
    }
\]
for $\mathbf{x} = (x_1, \dots, x_k) \in \R^k$ and $\mathbf{y} = (y_1, \dots, y_l) \in \R^l$.

In machine learning, $Y$ will often be some output resulting from a given input $X$. In particular, we often want to approximate or predict the value of $Y$ given some input $X$. That is, we want to find a measurable function
\[
    f \colon (\mathcal{X}, \mathcal{F}_{\mathcal{X}}) \to (\mathcal{Y}, \mathcal{F}_{\mathcal{Y}})
\]
mapping $X$ to $f(X)$ in such a way that $f(X)$ is \qq{close} to $Y$. In order to quantify this, we will need some functional
\[
    \mathcal{E} \colon \mathcal{Y} \times \mathcal{Y} \to \R
\]
that measures the error $\mathcal{E}(f(X), Y)$ of our prediction $f(X)$. For $\mathcal{Y} = \R^d$, a typical example is
\[
    \highlightMath{
        \mathcal{E}_p(Y_1, Y_2) = \Ex{\norm{Y_1 - Y_2}^p}, \quad p \geq 1,
    }
\]
where $\norm{\cdot}$ denotes the Euclidean norm on $\R^d$. For a measurable function $f \colon \mathcal{X} \to \R^d$, we write
\[
    \highlightMath{
        \mathcal{E}_p(f) = \mathcal{E}_p(f(X), Y) = \Ex{\norm{f(X) - Y}^p} = \int_{\mathcal{X} \times \mathcal{Y}} \norm{f(x) - y}^p \dP{(X, Y)}{x, y}.
    }
\]
A popular choice is $p = 2$, which yields the \emph{mean-squared error}
\[
    \mathcal{E}_2(f) = \ex{\norm{f(X) - Y}^2}.
\]
Minimizing the mean-squared error $\mathcal{E}_2(f)$ amounts to finding a measurable function $f \colon \mathcal{X} \to \R^d$ that minimizes the $L^2$-distance of $f(X)$ from $Y$. Recall that this is precisely what the \emph{conditional expectation} $\Ex{Y \given X}$ of $Y$ given $X$ does. Since the concept of conditional expectation is a vital one when it comes to statistical learning, we will briefly revisit its definition and some of its most important properties in the next section.
