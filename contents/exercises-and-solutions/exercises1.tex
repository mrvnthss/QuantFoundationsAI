%% PART ... %%
\part{Exercises \& Solutions}

%% CHAPTER ... %%
\chapter{Exercises}

%% EXERCISE SET 1 %%
\section{Exercise Set 1}

% EXERCISE 1
\begin{exercise}
In the setting of Proposition \ref{prop: decomposition of mean-squared error}, prove that
\[
    \Ex{(f_i(X) - \Ex{Y_i \given X}) (\Ex{Y_i \given X} - Y_i)} = 0
\]
for all $i = 1, \dots, d$, where $f_i \colon \mathcal{X} \to \R$ are measurable functions.
\end{exercise}


% EXERCISE 2
\begin{exercise}
Let $H$ be a random variable that almost surely takes values in the unit interval $[0, 1]$. Prove that
\[
    \Ex{\min(1-H, H)} = \frac{1}{2} - \frac{1}{2}\Ex{\abs{2H - 1}}.
\]
\end{exercise}


% EXERCISE 3
\begin{exercise}
Let $f^*$ be the Bayes classifier and let $L^*$ be the Bayes error. Prove that
\[
    \min_{f \colon \R^d \to \R} \Ex{\abs{f(X) - Y}} = \Ex{\abs{f^*(X) - Y}} = L^*.
\]
\end{exercise}


% EXERCISE 4
\begin{exercise}
Assume that $X$ has a density $f$ with respect to the Lebesgue measure, i.e.,
\[
    \P(X \in A) = \int_A f(x) \dx,
\]
and assume further that the class-conditional densities $f_i$ of $X$ given $Y = i$ exist for $i = 1, 2$, i.e.,
\[
    \P(X \in A \given Y = i) = \int_A f_i(x) \dx, \quad i = 1, 2.
\]
Finally, we denote the class probabilities by $p = \P(Y = 1) = 1 - \P(Y = 0)$. Prove that
\[
    \P(Y = 1 \given X = x) = \frac{f_1(x)p}{f_1(x)p + f_0(x) (1-p)}.
\]
\end{exercise}
