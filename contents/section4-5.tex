%% SECTION 4.5 %%
\section{Application to the ERM}

Recall our goal that we started with at the beginning of this chapter: given a family $\mathcal{H}$ of classifiers, we want to bound the excess risk $R(\hat h_n)$ of the empirical risk minimizer $\hat h$, which can be decomposed into estimation error and approximation error as follows:
\[
    R(\hat h) = \underbrace{L(\hat h) - L(\bar h)}_{\substack{\text{estimation} \\ \text{error}}} + \underbrace{L(\bar h) - L^*}_{\substack{\text{approximation} \\ \text{error}}}.
\]
Since the approximation error is fixed for a given family of classifiers $\mathcal{H}$, we have focused on bounding the estimation error $L(\hat h) - L(\bar h)$. In Lemma \ref{lem: bound on estimation error}, we had already observed that this estimation error is bounded by
\[
    L(\hat h) - L(\bar h) \leq 2 \, \sup_{h \in \mathcal{H}} \bigAbs{ \hat L_n(h) - L(h) }.
\]
Defining $A_h$ and $\mathcal{A}$ as in \eqref{eq: sets A_h} and \eqref{eq: collection of sets A_h}, respectively, i.e.,
\[
    A_h = \{ (x, y) \in \mathcal{X} \times \set{0, 1} \with h(x) \neq y \}, \quad \mathcal{A} = \set{A_h \with h \in \mathcal{H}},
\]
and letting $\mu(A) = \Pr{Z \in A}$ and $\mu_n(A) = n^{-1} \sum_{i=1}^n \indSet{Z_i \in A}$, we had observed that
\[
    \sup_{h \in \mathcal{H}} \bigAbs{ \hat L_n(h) - L(h) } = \sup_{A \in \mathcal{A}} \bigAbs{ \mu_n(A) - \mu(A) }.
\]
Hence, the VC inequality tells us that
\begin{equation}
\label{eq: VC ineqaulity for ERM}
    \highlightMath{
        \Pr{ \sup_{h \in \mathcal{H}} \bigAbs{ \hat L_n(h) - L(h) } < 2 \sqrt{\frac{2D \log(2 \e n / D)}{n}} + \sqrt{\frac{\log(\delta^{-1})}{2n}} } \geq 1 - \delta,
    }
\end{equation}
where $D$ denotes the VC dimension of $\mathcal{A} = \set{A_h \with h \in \mathcal{H}}$. However, the VC dimension of this class $\mathcal{A}$ is not very natural, and in many cases it is more convenient to consider the class
\begin{equation}
\label{eq: collection of sets bar A_h}
    \bar{\mathcal{A}} = \set{\bar A_h \with h \in \mathcal{H}}, \quad \bar A_h = \{ x \in \mathcal{X} \with h(x) = 1 \}.
\end{equation}
A priori it is not clear, how the VC dimension of the class $\mathcal{A}$ and the VC dimension of the class $\bar{\mathcal{A}}$ are related, if at all. However, as the next result shows, these two quantities actually coincide.

\begin{theorem}
Let $\mathcal{H}$ be a family of classifiers and let $\mathcal{A}$ and $\bar{\mathcal{A}}$ be defined as in \eqref{eq: collection of sets A_h} and \eqref{eq: collection of sets bar A_h}, respectively. Then,
\[
    \mathcal{S}_{\mathcal{A}}(n) = \mathcal{S}_{\bar{\mathcal{A}}}(n), \quad n \geq 1,
\]
which implies that $VC(\mathcal{A}) = VC(\bar{\mathcal{A}})$.
\end{theorem}

\begin{proof}
Recall that the $n$-th shatter coefficent $\mathcal{S}_{\mathcal{A}}(n)$ is defined by $\mathcal{S}_{\mathcal{A}}(n) = \sup_{z_1, \dots, z_n} \card{T(z)}$, where $T(z)$ is the set of binary patterns that can be generated by the set $z = \set{z_1, \dots, z_n} \subset \mathcal{Z}$, i.e.,
\[
    T(z) = \set{(\indSet{z_1 \in A}, \dots, \indSet{z_n \in A}) \with A \in \mathcal{A}}, \quad z_i = (x_i, y_i) \in \mathcal{X} \times \set{0, 1}.
\]
By definition of the collection of sets $\mathcal{A}$ in \eqref{eq: collection of sets A_h}, we can rewrite this as
\[
    T(z) = \set{(\indSet{h(x_1) \neq y_1}, \dots, \indSet{h(x_n) \neq y_n}) \with h \in \mathcal{H}}.
\]
Similarly, let $\bar T(z)$ denote the set of binary patterns generated by the set $z$ for the collection of sets $\bar{\mathcal{A}}$ defined in \eqref{eq: collection of sets bar A_h}, i.e.,
\[
    \bar T(z) = \set{(\indSet{h(x_1) = 1}, \dots, \indSet{h(x_n) = 1}) \with h \in \mathcal{H}}.
\]
Next, we fix $v \in \set{0, 1}$ and let $u \oplus v$ denote the logical XOR operation applied to $u \in \set{0, 1}$, i.e.,
\[
    \oplus \colon \set{0, 1} \to \set{0, 1}, \quad u \mapsto u \oplus v = \indSet{u \neq v}.
\]
The XOR operation is an involution, i.e., it satisfies $(u \oplus v) \oplus v = u$. In particular, the XOR operation is bijective. By applying the XOR operation to each entry of a vector, we have
\[
    \begin{pmatrix}
        \indSet{h(x_1) \neq y_1} \\
        \vdots \\
        \indSet{h(x_n) \neq y_n}
    \end{pmatrix} =
    \begin{pmatrix}
        \indSet{h(x_1) = 1} \\
        \vdots \\
        \indSet{h(x_n) = 1}
    \end{pmatrix} \oplus
    \begin{pmatrix}
        y_1 \\
        \vdots \\
        y_n
    \end{pmatrix}.
\]
Since the XOR operation is bijective, this tells us that the cardinalities of $T(z)$ and $\bar T(z)$ coincide. Consequently, so do the shatter coefficients and the VC dimension of the collections $\mathcal{A}$ and $\bar{\mathcal{A}}$.
\end{proof}

Based on our discussion of the emprical risk minimzer at the beginning of this section, we conclude the following:

\begin{corollary}
The empirical risk minimizer $\hat h$ of a family of classifiers $\mathcal{H}$ with VC dimension $D$ satisfies
\[
    L(\hat h) < L(\bar h) + 4 \sqrt{\frac{2D \log(2 \e n / D)}{n}} + 2 \sqrt{\frac{\log(\delta^{-1})}{2n}}
\]
with probability at least $1 - \delta$.
\end{corollary}
